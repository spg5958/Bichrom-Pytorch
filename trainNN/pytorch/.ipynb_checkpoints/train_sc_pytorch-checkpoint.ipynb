{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de0ff82",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/storage/home/spg5958/work/software/miniconda3/envs/pytorch2/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from train_seq_pytorch import Params,bichrom_seq,build_seq_model\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fd155af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256, 27])\n",
      "torch.Size([1, 256, 27])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0305, -0.0023]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_model = build_seq_model(Params())\n",
    "base_model.load_state_dict(torch.load(\"seq_model.torch\"))\n",
    "activation = {}\n",
    "def get_activation(name):\n",
    "    def hook(seq_model, input, output):\n",
    "        activation[name] = output.detach()\n",
    "    return hook\n",
    "base_model.model_dense_repeat[7].register_forward_hook(get_activation('dense_2'))\n",
    "x=torch.randn(1,4,50)\n",
    "out=base_model(x)\n",
    "curr_tensor=activation['dense_2']\n",
    "xs=nn.Linear(512, 2)(curr_tensor)\n",
    "xs=nn.Tanh()(xs)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "11dd25eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bichrom_sc(nn.Module):\n",
    "    def __init__(self, no_of_chromatin_tracks):\n",
    "        super().__init__()\n",
    "        self.conv1d=nn.Conv1d(no_of_chromatin_tracks, 15, 1, padding=\"valid\")\n",
    "        self.relu=nn.ReLU()\n",
    "        self.lstm=nn.LSTM(15, 5, batch_first=True)\n",
    "        self.linear=nn.Linear(5, 1)\n",
    "        self.tanh=nn.Tanh()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        xc=self.conv1d(x)\n",
    "        xc=self.relu(xc)\n",
    "        xc=torch.permute(xc, (0, 2, 1))\n",
    "        xc=self.lstm(xc)[0][:, -1, :]\n",
    "        xc=self.linear(xc)\n",
    "        xc=self.tanh(xc)\n",
    "        return xc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "71e163c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bichrom_sc(12)(torch.randn(1,12,1000)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2027e93e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_new_layers():\n",
    "    base_model = build_seq_model(Params())\n",
    "    base_model.load_state_dict(torch.load(\"seq_model.torch\"))\n",
    "    activation = {}\n",
    "    def get_activation(name):\n",
    "        def hook(seq_model, input, output):\n",
    "            activation[name] = output.detach()\n",
    "        return hook\n",
    "    base_model.model_dense_repeat[7].register_forward_hook(get_activation('dense_2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2cff9ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bichrom(nn.Module):\n",
    "    def __init__(self,base_model,no_of_chromatin_tracks):\n",
    "        super().__init__()\n",
    "        self.base_model=base_model\n",
    "        self.activation = {}\n",
    "        def get_activation(name):\n",
    "            def hook(seq_model, input, output):\n",
    "                self.activation[name] = output.detach()\n",
    "            return hook\n",
    "        self.base_model.model_dense_repeat[7].register_forward_hook(get_activation('dense_2'))\n",
    "        self.linear=nn.Linear(512, 1)\n",
    "        self.tanh=nn.Tanh()\n",
    "        self.model=bichrom_sc(no_of_chromatin_tracks)\n",
    "        self.linear2=nn.Linear(2, 1)\n",
    "        self.sigmoid=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,seq_input, chromatin_input):\n",
    "        self.base_model(seq_input)\n",
    "        curr_tensor=self.activation['dense_2']\n",
    "        xs=self.linear(curr_tensor)\n",
    "        xs=self.tanh(xs)\n",
    "        print(xs.shape)\n",
    "        xc=self.model(chromatin_input)\n",
    "        print(xc.shape)\n",
    "        xsc = torch.cat((xs, xc), dim=1)\n",
    "        xsc=self.linear2(xsc)\n",
    "        result=self.sigmoid(xsc)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a3919c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 256, 977])\n",
      "torch.Size([2, 256, 977])\n",
      "torch.Size([2, 1])\n",
      "torch.Size([2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.5029],\n",
       "        [0.5084]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bichrom(base_model,12)(torch.rand(2,4,1000),torch.randn(2,12,500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb03ec1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fd7ba8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch2] *",
   "language": "python",
   "name": "conda-env-pytorch2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
